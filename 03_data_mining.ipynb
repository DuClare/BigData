{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === 1. Data Loading and Exploration ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Data Loading and Exploration ===\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, silhouette_score\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Load the dataset\n",
    "csv_file = \"data/eco2mix.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Convert 'Date - Time' to datetime format\n",
    "df['Date - Time'] = pd.to_datetime(df['Date - Time'])\n",
    "\n",
    "# Inspect the dataset\n",
    "print(\"Dataset Overview:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst Few Rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analysis:**  \n",
    " - This dataset contains detailed information about energy production and consumption across different regions and energy sources.  \n",
    " - Key columns include `Consumption (MW)`, `Production (MW)`, `Wind (MW)`, `Solar (MW)`, `Hydraulic (MW)`, and timestamps (`Date - Time`).  \n",
    " - Our goal is to analyze, cluster, and predict trends while exploring the dataset comprehensively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === 3. Clustering with Optimal Cluster Selection ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Clustering with Optimal Cluster Selection ===\n",
    "\n",
    "\n",
    "# Use a subset of data (1%) for efficient calculation of optimal clusters\n",
    "subset = df.sample(frac=0.01, random_state=42)\n",
    "subset_metrics = subset[['Consumption (MW)', 'Production (MW)', 'Wind (MW)', 'Solar (MW)', 'Hydraulic (MW)']].dropna()\n",
    "\n",
    "# Scale the subset data\n",
    "scaler = StandardScaler()\n",
    "scaled_subset_metrics = scaler.fit_transform(subset_metrics)\n",
    "\n",
    "# Determine the optimal number of clusters using Elbow Method and Silhouette Scores\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "range_n_clusters = range(2, 11)\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(scaled_subset_metrics)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(scaled_subset_metrics, cluster_labels))\n",
    "\n",
    "# Plot Elbow Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_n_clusters, inertia, marker='o', linestyle='--')\n",
    "plt.title(\"Elbow Method for Optimal Clusters (Subset)\", fontsize=16)\n",
    "plt.xlabel(\"Number of Clusters\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Plot Silhouette Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_n_clusters, silhouette_scores, marker='o', linestyle='--', color='orange')\n",
    "plt.title(\"Silhouette Scores for Optimal Clusters (Subset)\", fontsize=16)\n",
    "plt.xlabel(\"Number of Clusters\", fontsize=14)\n",
    "plt.ylabel(\"Silhouette Score\", fontsize=14)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Select the optimal number of clusters based on silhouette scores\n",
    "optimal_clusters = list(range_n_clusters)[np.argmax(silhouette_scores)]\n",
    "print(f\"Optimal number of clusters based on subset: {optimal_clusters}\")\n",
    "\n",
    "# Apply optimal clustering to the full dataset\n",
    "full_metrics = df[['Consumption (MW)', 'Production (MW)', 'Wind (MW)', 'Solar (MW)', 'Hydraulic (MW)']].dropna()\n",
    "scaled_full_metrics = scaler.transform(full_metrics)\n",
    "\n",
    "# Apply clustering to the subset\n",
    "kmeans_subset = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "subset['Cluster'] = kmeans_subset.fit_predict(scaled_subset_metrics)\n",
    "\n",
    "# Visualize clustering for the 1% subset\n",
    "plt.figure(figsize=(10, 6))\n",
    "markers = ['o', 's', 'D', '^', 'P', '*', 'X']  # Define different marker styles\n",
    "\n",
    "for cluster in range(optimal_clusters):\n",
    "    cluster_data = subset[subset['Cluster'] == cluster]\n",
    "    plt.scatter(\n",
    "        cluster_data['Production (MW)'], \n",
    "        cluster_data['Consumption (MW)'], \n",
    "        label=f'Cluster {cluster}', \n",
    "        alpha=0.7, \n",
    "        marker=markers[cluster % len(markers)]  # Cycle through markers\n",
    "    )\n",
    "\n",
    "plt.title(\"Clustering of Regions (1% Subset Data)\", fontsize=16)\n",
    "plt.xlabel(\"Production (MW)\", fontsize=14)\n",
    "plt.ylabel(\"Consumption (MW)\", fontsize=14)\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analysis:**  \n",
    " - Using a subset of the data ensures efficient calculation of the optimal cluster number.  \n",
    " - The Elbow Method and Silhouette Scores indicate the best k-value for clustering.  \n",
    " - Applying the determined number of clusters to the full dataset groups regions effectively.  \n",
    " - The scatterplot shows distinct clusters, providing actionable insights into energy production and consumption patterns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === 4. Outlier Detection ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Outlier Detection ===\n",
    "\n",
    "# Compute Z-scores\n",
    "df['Production_Zscore'] = zscore(df['Production (MW)'])\n",
    "df['Consumption_Zscore'] = zscore(df['Consumption (MW)'])\n",
    "\n",
    "# Identify and Analyze Outliers\n",
    "production_outliers = df[np.abs(df['Production_Zscore']) > 3]\n",
    "consumption_outliers = df[np.abs(df['Consumption_Zscore']) > 3]\n",
    "\n",
    "print(f\"Number of production outliers: {len(production_outliers)}\")\n",
    "print(f\"Number of consumption outliers: {len(consumption_outliers)}\")\n",
    "\n",
    "# Visualize Outliers in Production and Consumption\n",
    "fig = px.scatter(df, x='Production (MW)', y='Consumption (MW)', \n",
    "                 color=np.abs(df['Production_Zscore']) > 3, \n",
    "                 title=\"Outlier Detection in Production and Consumption\",\n",
    "                 labels={\"color\": \"Production Outlier\"})\n",
    "fig.show()\n",
    "\n",
    "# Explore Outliers for Specific Regions\n",
    "top_outlier_regions = production_outliers['Region'].value_counts().head()\n",
    "print(\"\\nTop Regions with Production Outliers:\\n\", top_outlier_regions)\n",
    "\n",
    "# Visualize Outlier Trends Over Time\n",
    "fig = px.line(production_outliers, x='Date - Time', y='Production (MW)', color='Region',\n",
    "              title=\"Production Outliers Over Time by Region\",\n",
    "              labels={\"Region\": \"Outlier Region\"})\n",
    "fig.show()\n",
    "\n",
    "fig = px.line(consumption_outliers, x='Date - Time', y='Consumption (MW)', color='Region',\n",
    "              title=\"Consumption Outliers Over Time by Region\",\n",
    "              labels={\"Region\": \"Outlier Region\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analysis:**  \n",
    " - Significant outliers in production and consumption highlight rare events or anomalies.  \n",
    " - Specific regions dominate outlier counts, suggesting potential localized issues or unique conditions.  \n",
    " - Time-series visualizations of outliers provide insights into the timing and frequency of these anomalies.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === 5. Optimized Prediction ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Optimized Prediction  ===\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure the 'Month' and 'Hour' columns are extracted\n",
    "df['Month'] = pd.to_datetime(df['Date - Time']).dt.month  # Extract month\n",
    "df['Hour'] = pd.to_datetime(df['Date - Time']).dt.hour   # Extract hour\n",
    "\n",
    "# Select relevant features based on correlation\n",
    "features = ['Production (MW)', 'Hydraulic (MW)', 'Month', 'Hour']\n",
    "target = 'Consumption (MW)'\n",
    "\n",
    "# Prepare the dataset\n",
    "X = df.dropna(subset=features + [target])[features]\n",
    "y = df.dropna(subset=features + [target])[target]\n",
    "\n",
    "# Train-test split (80% Train, 20% Test)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train LightGBM Model\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=200, max_depth=15, learning_rate=0.1, num_leaves=100, random_state=42, n_jobs=-1)\n",
    "lgb_model.fit(train_X, train_y)\n",
    "\n",
    "# Predict and Evaluate\n",
    "lgb_pred_y = lgb_model.predict(test_X)\n",
    "lgb_mse = mean_squared_error(test_y, lgb_pred_y)\n",
    "lgb_rmse = np.sqrt(lgb_mse)\n",
    "lgb_mae = mean_absolute_error(test_y, lgb_pred_y)\n",
    "\n",
    "print(f\"LightGBM MSE: {int(lgb_mse)}\")\n",
    "print(f\"LightGBM RMSE: {int(lgb_rmse)}\")\n",
    "print(f\"LightGBM MAE: {int(lgb_mae)}\")\n",
    "\n",
    "# Visualize Predictions (Actual vs Predicted)\n",
    "fig = px.scatter(x=test_y, y=lgb_pred_y, \n",
    "                 title=\"Actual vs Predicted Consumption (LightGBM)\",\n",
    "                 labels={\"x\": \"Actual Consumption\", \"y\": \"Predicted Consumption\"})\n",
    "fig.update_traces(marker=dict(size=5, opacity=0.7))\n",
    "fig.show()\n",
    "\n",
    "# Feature Importance\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': lgb_model.feature_importances_})\n",
    "fig = px.bar(importance_df.sort_values(by=\"Importance\", ascending=False), \n",
    "             x='Feature', y='Importance', \n",
    "             title=\"Feature Importance in LightGBM Model\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analysis:**  \n",
    " - LightGBM provides an efficient solution for large datasets, balancing speed and accuracy.  \n",
    " - The feature importance chart highlights key variables influencing consumption predictions.  \n",
    " Best Parameters for LightGBM: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 200, 'num_leaves': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# === Enhanced Visualization ===\n",
    "\n",
    "# 1. Scatter Plot: Actual vs Predicted with Ideal Line\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add actual vs predicted scatter points\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_y, \n",
    "    y=lgb_pred_y, \n",
    "    mode='markers', \n",
    "    name='Predictions',\n",
    "    marker=dict(size=5, opacity=0.7)\n",
    "))\n",
    "\n",
    "# Add perfect line (y=x)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[test_y.min(), test_y.max()],\n",
    "    y=[test_y.min(), test_y.max()],\n",
    "    mode='lines',\n",
    "    name='Ideal Line',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Actual vs Predicted Consumption (LightGBM)\",\n",
    "    xaxis_title=\"Actual Consumption (MW)\",\n",
    "    yaxis_title=\"Predicted Consumption (MW)\",\n",
    "    legend_title=\"Legend\",\n",
    "    width=800, height=600\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# 2. Residual Plot\n",
    "residuals = test_y - lgb_pred_y\n",
    "fig = px.scatter(\n",
    "    x=lgb_pred_y, \n",
    "    y=residuals, \n",
    "    labels={'x': 'Predicted Consumption (MW)', 'y': 'Residuals (MW)'},\n",
    "    title='Residual Plot (LightGBM Predictions)'\n",
    ")\n",
    "fig.update_traces(marker=dict(size=5, opacity=0.7))\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"red\")  # Add a horizontal line at residual=0\n",
    "fig.show()\n",
    "\n",
    "# 3. Distribution Plot: Actual vs Predicted\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add distribution for actual values\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=test_y, \n",
    "    name='Actual', \n",
    "    opacity=0.6, \n",
    "    marker_color='blue'\n",
    "))\n",
    "\n",
    "# Add distribution for predicted values\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=lgb_pred_y, \n",
    "    name='Predicted', \n",
    "    opacity=0.6, \n",
    "    marker_color='orange'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Distribution of Actual vs Predicted Consumption\",\n",
    "    barmode='overlay',\n",
    "    xaxis_title=\"Consumption (MW)\",\n",
    "    yaxis_title=\"Frequency\",\n",
    "    legend_title=\"Legend\",\n",
    "    width=800, height=600\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# 4. Feature Importance (Horizontal Bar Chart)\n",
    "importance_df_sorted = importance_df.sort_values(by=\"Importance\", ascending=True)\n",
    "\n",
    "fig = px.bar(\n",
    "    importance_df_sorted, \n",
    "    x='Importance', \n",
    "    y='Feature', \n",
    "    orientation='h', \n",
    "    title=\"Feature Importance (LightGBM)\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Importance Score\",\n",
    "    yaxis_title=\"Features\",\n",
    "    width=800, height=600\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Residuals Heatmap by Hour and Month\n",
    "df_test = df.loc[test_X.index].copy()\n",
    "df_test['Residuals'] = residuals\n",
    "\n",
    "heatmap_data = df_test.pivot_table(\n",
    "    values='Residuals', \n",
    "    index='Hour', \n",
    "    columns='Month', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "fig = px.imshow(\n",
    "    heatmap_data, \n",
    "    labels={'color': 'Residuals (MW)', 'x': 'Month', 'y': 'Hour'},\n",
    "    title=\"Average Residuals by Hour and Month\",\n",
    "    color_continuous_scale='RdBu_r'\n",
    ")\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()\n",
    "\n",
    "# Time-Series of Actual vs Predicted\n",
    "test_y_index = test_y.reset_index(drop=True)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add actual values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_y_index.index, \n",
    "    y=test_y_index, \n",
    "    mode='lines', \n",
    "    name='Actual', \n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "# Add predicted values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_y_index.index, \n",
    "    y=lgb_pred_y, \n",
    "    mode='lines', \n",
    "    name='Predicted', \n",
    "    line=dict(color='orange')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Time-Series of Actual vs Predicted Consumption\",\n",
    "    xaxis_title=\"Index (Time Ordered)\",\n",
    "    yaxis_title=\"Consumption (MW)\",\n",
    "    legend_title=\"Legend\",\n",
    "    width=800, height=600\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analysis:**  \n",
    "- Strong agreement between actual and predicted consumption values. \n",
    "- Bar chart highlights the key predictors influencing energy consumption.\n",
    "- Time series comparison of actual vs predicted consumption reveals systematic trends and residual errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === OPTIONAL: Best Parameters for LightBGM ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Define a parameter grid for LightGBM\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Create the LightGBM model\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "# Get the best parameters and train the model\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters for LightGBM: {best_params}\")\n",
    "\n",
    "# Train the model with the best parameters\n",
    "optimized_lgb_model = lgb.LGBMRegressor(**best_params, random_state=42)\n",
    "optimized_lgb_model.fit(train_X, train_y)\n",
    "\n",
    "# Predict and evaluate the optimized model\n",
    "optimized_pred_y = optimized_lgb_model.predict(test_X)\n",
    "optimized_mse = mean_squared_error(test_y, optimized_pred_y)\n",
    "optimized_rmse = np.sqrt(optimized_mse)\n",
    "optimized_mae = mean_absolute_error(test_y, optimized_pred_y)\n",
    "\n",
    "print(f\"Optimized LightGBM MSE: {int(optimized_mse)}\")\n",
    "print(f\"Optimized LightGBM RMSE: {int(optimized_rmse)}\")\n",
    "print(f\"Optimized LightGBM MAE: {int(optimized_mae)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
